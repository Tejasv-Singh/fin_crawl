# ğŸš¨ FINCRAWL â€” Autonomous Financial Filings Early-Warning System

**AI-powered risk detection from SEC filings, corporate disclosures, and financial news.**

FINCRAWL is an autonomous financial intelligence platform that continuously ingests SEC EDGAR filings and news streams, processes them with RAG (Retrieval-Augmented Generation), and detects high-risk signals such as going-concern warnings, material weaknesses, accounting anomalies, distress clues, and fraud indicators.

Designed as a hackathon-ready MVP, FINCRAWL combines intelligent ingestion, semantic search, automated reasoning, and real-time dashboards â€” enabling analysts, investors, auditors, and regulators to understand emerging risks before markets react.

## âœ¨ Key Features

### âš™ï¸ Autonomous Ingestion Pipeline
- Crawls SEC EDGAR filings (10-K, 10-Q, 8-K).
- Monitors RSS financial news feeds in real time.
- Extracts text from HTML/PDF filings.
- Normalizes documents into structured JSON.

### ğŸ” Semantic RAG Engine
- Embeds filings using SentenceTransformers.
- Stores vectors in ChromaDB for fast similarity search.
- Provides source-grounded, citation-backed answers using a lightweight RAG pipeline.

### ğŸš¨ Risk Scoring & Event Detection
- **Detects red-flag patterns including:**
  - â€œGoing concernâ€ remarks
  - â€œMaterial weakness in internal controlsâ€
  - Executive resignations
  - Litigation disclosures
  - Sudden financial restatements
  - Negative sentiment shifts
  - Bankruptcy precursors
- **Scores are produced by a hybrid engine:**
  - Rule-based heuristics
  - Pattern classifiers
  - Semantic similarity to known risk templates

### ğŸ“Š Premium Interactive Dashboard
- **Bloomberg-Style Dark Mode Interface**: Premium glassmorphism design for high-contrast professional use.
- **AI Risk Analysis Modal**: Click "Analyze" to get an instant, explanation of the risk score (Critical/Warning/Stable) and detected signals.
- **Live Risk Feed**: Real-time streaming of risk scores with "Refresh to Crawl" capability.
- **Visualizations**: Risk distribution and volatility metrics.
- **Deep-Links**: Direct access to source filings for verification.

## ğŸ—ï¸ Architecture Overview

```mermaid
graph TD
    subgraph Data_Sources [External Data]
        SEC["SEC EDGAR (10-K/8-K)"]
        RSS["Financial News RSS"]
    end

    subgraph Backend [FastAPI + Celery Engine]
        Crawler[Async Crawler]
        Parser[Text Parser]
        Scorer[Risk Signal Engine]
        Embedder[Vector Embedder]
    end

    subgraph Persistence [Local-First Storage]
        SQLite[("SQLite Metadata")]
        Chroma[("ChromaDB Vectors")]
        FS[("Local Filesystem")]
    end

    subgraph Frontend [React Deployment]
        UI[Dashboard UI]
        Viz[Risk Visualizations]
        Analysis[AI Analysis Modal]
    end

    %% Ingestion Flow
    SEC --> Crawler
    RSS --> Crawler
    Crawler --> Parser
    
    %% Processing Flow
    Parser --> FS
    Parser --> SQLite
    Parser --> Scorer
    Parser --> Embedder
    
    %% Storage Flow
    Scorer -->|Risk Score| SQLite
    Embedder -->|Embeddings| Chroma
    
    %% User Flow
    SQLite -->|JSON Data| UI
    Chroma -->|RAG Search| UI
    Scorer -->|Alerts| Viz
```

## ğŸ§° Tech Stack

- **Backend**: Python 3.10+, FastAPI, Celery (async workers), ChromaDB (vector store), SQLite, SentenceTransformers
- **Frontend**: React + Vite, TailwindCSS, Recharts
- **Infrastructure**: Local development (No Docker needed), Makefile-based orchestration, Lightweight deployment

## ğŸš€ Quick Start

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/Tejasv-Singh/FINCRAWL
cd FINCRAWL
```

### 2ï¸âƒ£ Backend Setup
```bash
python3 -m venv venv
source venv/bin/activate
pip install -r backend/requirements.txt
```

Run backend:
```bash
make run-backend
```
Backend runs at â†’ `http://localhost:8001`

### 3ï¸âƒ£ Frontend Setup
```bash
cd frontend
npm install
npm run dev
```
Frontend runs at â†’ `http://localhost:5173`

### 4ï¸âƒ£ Start Full System
```bash
make run-all
```
This launches:
- FastAPI backend
- RAG engine
- React dashboard

## ğŸš€ Deployment

### Backend (Render)
Click below to deploy the Backend + Worker + Database to Render.com (Auto-configured).

[![Deploy to Render](https://render.com/images/deploy-to-render-button.svg)](https://render.com/deploy?repo=https://github.com/Tejasv-Singh/FINCRAWL)

### Frontend (GitHub Pages)
The Repository enables `GitHub Pages` automatically via GitHub Actions.
1. Go to Repo Settings -> Pages -> Source: `GitHub Actions`.
2. The dashboard will be live at `https://tejasv-singh.github.io/fin_crawl/`.
3. **Important**: You must configure the Frontend to talk to the Backend.
   - Go to Repo Settings -> Secrets and variables -> Actions -> New Repository Variable.
   - Name: `VITE_API_URL`
   - Value: `https://your-render-backend-url.onrender.com/api/v1` (Get this from Render Dashboard).

## ğŸ“‘ Data Ingestion

To manually trigger document ingestion:
```bash
make crawl
```
This supports SEC EDGAR RSS feeds and Company filings (10-K, 8-K).

## ğŸ§ª Backtesting

Evaluate the risk-scoring engine against historical filings:
```bash
make backtest
```
Outputs: Precision/Recall and Risk validation status.

## ğŸ“‚ Project Structure

```bash
FINCRAWL/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/          # FastAPI routes
â”‚   â”‚   â”œâ”€â”€ crawlers/     # SEC EDGAR + RSS crawlers
â”‚   â”‚   â”œâ”€â”€ parsers/      # Parsing logic
â”‚   â”‚   â”œâ”€â”€ services/     # Scoring, Alerting, VectorDB
â”‚   â”‚   â”œâ”€â”€ worker/       # Celery tasks
â”‚   â”‚   â””â”€â”€ db/           # Database models
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/   # UI components
â”‚   â”‚   â””â”€â”€ App.tsx       # Main view
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ backtest_scoring.py
â”‚
â”œâ”€â”€ Makefile
â””â”€â”€ README.md
```

## ğŸ§  Roadmap (Post-Hackathon)
- [ ] Whisper-powered earnings call transcription
- [ ] Advanced anomaly detection (Autoencoders, BERT-based classifiers)
- [ ] Multi-jurisdiction filings (SEBI, FCA, ASX)
- [ ] Real-time alert system (Slack/Email)
- [ ] Multi-agent â€œAnalyst Copilotâ€
- [ ] Full company knowledge graph
- [ ] Sentiment delta modeling

## â¤ï¸ Acknowledgements
FINCRAWL was built for **SNOW FEST Hackathon 2025**, with the mission of democratizing financial risk intelligence.

## ğŸ“¬ Contact
- **Developer**: Tejasv Singh
- **GitHub**: [https://github.com/Tejasv-Singh](https://github.com/Tejasv-Singh)
